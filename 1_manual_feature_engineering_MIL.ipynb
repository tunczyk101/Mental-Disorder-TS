{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320837f7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "18e18bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:13:02.646087Z",
     "start_time": "2024-12-05T15:12:45.287793Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import warnings\n",
    "\n",
    "from adodbapi.process_connect_string import process\n",
    "from pyarrow.dataset import dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from utils import Dataset, variance_thresholding, standardize, mcc, calculate_metrics, calculate_metrics_statistics, DatasetWin, calculate_metrics_from_df"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b84c8514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:13:02.691680Z",
     "start_time": "2024-12-05T15:13:02.671864Z"
    }
   },
   "source": [
    "# parameters for Welch's method for estimating power spectrum\n",
    "\n",
    "NPERSEG = 60                    # length of segment\n",
    "NOVERLAP = int(0.75 * NPERSEG)  # overlap of segments\n",
    "NFFT = NPERSEG                  # length of FFT\n",
    "WINDOW = \"hann\"                 # window function type\n",
    "\n",
    "# parameters for saving data\n",
    "PROCESSED_DATA_DIR = \"processed_data\"\n",
    "DEPRESJON_PREFIX = \"manual_depresjon\"\n",
    "PSYKOSE_PREFIX = \"manual_psykose\"\n",
    "HYPERAKTIV_PREFIX = \"manual_hyperaktiv\"\n",
    "MAIN_RESULTS_DIR = \"results\"\n",
    "DAY_WINDOWS_DIR = \"day_windows\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "44ef0d95",
   "metadata": {},
   "source": [
    "# Manual feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9515d10",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "657c3d7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:14:42.570581Z",
     "start_time": "2024-12-05T15:14:42.532865Z"
    }
   },
   "source": [
    "def basic_data_cleaning(data: List[List[pd.DataFrame]]) -> List[List[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Assumes DataFrames with \"timestamp\", \"date\" and \"activity\" columns.\n",
    "    \n",
    "    Performs cleaning operations:\n",
    "    - Format \"timestamp\" to YYYY-MM-DD HH:MM:SS\n",
    "    - Drop redundant \"date\" column\n",
    "    - Convert \"activity\" to float32\n",
    "    \n",
    "    :param data: list of DataFrames\n",
    "    :returns: list of cleaned DataFrames\n",
    "    \"\"\"\n",
    "    data = [df.copy() for df in data]  # create copy to avoid side effects\n",
    "    for patient in data:\n",
    "        for df in patient:\n",
    "            # Convert and enforce the desired timestamp format\n",
    "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], dayfirst=False)\n",
    "            df[\"timestamp\"] = df[\"timestamp\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "            # Drop \"date\" column if it exists\n",
    "            if \"date\" in df.columns:\n",
    "                df.drop(\"date\", axis=1, inplace=True)\n",
    "            \n",
    "            # Ensure \"activity\" column is float32\n",
    "            df[\"activity\"] = df[\"activity\"].astype(np.float32)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_day_part(df: pd.DataFrame, part: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For given DataFrame with \"timestamp\" column returns only those rows that\n",
    "    correspond to the chosen part of day.\n",
    "    \n",
    "    Parts are \"day\" and \"night\", defined as:\n",
    "    - \"day\": [8:00, 21:00)\n",
    "    - \"night\": [21:00, 8:00)\n",
    "    \n",
    "    :param df: DataFrame to select rows from\n",
    "    :param part: part of day, either \"day\" or \"night\"\n",
    "    :returns: DataFrame, subset of rows of df\n",
    "    \"\"\"\n",
    "    if part == \"day\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 8) &\n",
    "                    (df[\"timestamp\"].dt.hour < 21)]\n",
    "    elif part == \"night\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 21) |\n",
    "                    (df[\"timestamp\"].dt.hour < 8)]\n",
    "    else:\n",
    "        raise ValueError(f'Part should be \"day\" or \"night\", got \"{part}\"')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_activity(df: pd.DataFrame, freq: str = \"min\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fill missing activity values by resampling based on given frequency.\n",
    "    \n",
    "    :param df: DataFrame with 'timestamp' and 'activity' columns.\n",
    "    :param freq: Resampling frequency (default: minute).\n",
    "    :return: DataFrame with missing values filled.\n",
    "    \"\"\"\n",
    "    df = df.copy() # create copy to avoid side effects\n",
    "  \n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "    df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "    # resample to the basic frequency, i.e. minute; this will create NaNs for\n",
    "    # any rows that may be missing\n",
    "    df = df.resample(freq).mean()\n",
    "    \n",
    "    # recreate index and \"timestamp\" column\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # fill any NaNs with mean activity value\n",
    "    df[\"activity\"] = df[\"activity\"].fillna(df[\"activity\"].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def resample(df: pd.DataFrame, freq: str = \"H\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resamples time series DataFrame with given frequency, aggregating each\n",
    "    segment with a mean.\n",
    "\n",
    "    :param df: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency passed to Pandas resample() function\n",
    "    :returns: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # group with given frequency\n",
    "    df = df.resample(freq, on=\"timestamp\").mean()\n",
    "\n",
    "    # recreate \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def proportion_of_zeros(x: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates proportion of zeros in given array, i.e. number of zeros divided\n",
    "    by length of array.\n",
    "    \n",
    "    :param x: 1D Numpy array\n",
    "    :returns: proportion of zeros\n",
    "    \"\"\"\n",
    "    # we may be dealing with floating numbers, we can't use direct comparison\n",
    "    zeros_count = np.sum(np.isclose(x, 0))\n",
    "    return zeros_count / len(x)\n",
    "\n",
    "\n",
    "def power_spectral_density(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates power spectral density (PSD) from \"activity\" column of a\n",
    "    DataFrame.\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: 1D Numpy array with power spectral density\n",
    "    \"\"\"\n",
    "\n",
    "    activity = df[\"activity\"].values\n",
    "    nperseg = min(NPERSEG, len(activity))  # Ensure nperseg doesn't exceed data length\n",
    "    noverlap = int(0.75 * nperseg) \n",
    "    \n",
    "    psd = scipy.signal.welch(\n",
    "        x=activity,\n",
    "        fs=(1/60),\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap,\n",
    "        nfft=NFFT,\n",
    "        window=WINDOW,\n",
    "        scaling=\"density\"\n",
    "    )[1]\n",
    "    return psd\n",
    "\n",
    "\n",
    "def spectral_flatness(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculates spectral flatness of a signal, i.e. a geometric mean of the\n",
    "    power spectrum divided by the arithmetic mean of the power spectrum.\n",
    "    \n",
    "    If some frequency bins in the power spectrum are close to zero, they are\n",
    "    removed prior to calculation of spectral flatness to avoid calculation of\n",
    "    log(0).\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: spectral flatness value\n",
    "    \"\"\"\n",
    "\n",
    "    activity = df[\"activity\"].values\n",
    "    nperseg = min(NPERSEG, len(activity))  # Ensure nperseg doesn't exceed data length\n",
    "    noverlap = int(0.75 * nperseg) \n",
    "\n",
    "    power_spectrum = scipy.signal.welch(\n",
    "        activity,\n",
    "        fs=(1/60),\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap,\n",
    "        nfft=NFFT,\n",
    "        window=WINDOW,\n",
    "        scaling=\"spectrum\"\n",
    "    )[1]\n",
    "    \n",
    "    non_zeros_mask = ~np.isclose(power_spectrum, 0)\n",
    "    power_spectrum = power_spectrum[non_zeros_mask]\n",
    "    \n",
    "    return scipy.stats.gmean(power_spectrum) / power_spectrum.mean()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "7c465a53",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "id": "16826d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:14:45.537495Z",
     "start_time": "2024-12-05T15:14:45.514638Z"
    }
   },
   "source": [
    "def extract_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts features from activity signal in time domain.\n",
    "    \n",
    "    :param df_resampled: DataFrame with \"activity\" column\n",
    "    :returns: DataFrame with a single row representing features\n",
    "    \"\"\"\n",
    "    X = df[\"activity\"].values\n",
    "    \n",
    "    features = {\n",
    "        \"minimum\": np.min(X),\n",
    "        \"maximum\": np.max(X),\n",
    "        \"mean\": np.mean(X),\n",
    "        \"median\": np.median(X),\n",
    "        \"variance\": np.var(X, ddof=1),  # apply Bessel's correction\n",
    "        \"kurtosis\": sp.stats.kurtosis(X),\n",
    "        \"skewness\": sp.stats.skew(X),\n",
    "        \"coeff_of_var\": sp.stats.variation(X),\n",
    "        \"iqr\": sp.stats.iqr(X),\n",
    "        \"trimmed_mean\": sp.stats.trim_mean(X, proportiontocut=0.1),\n",
    "        \"entropy\": sp.stats.entropy(X, base=2),\n",
    "        \"proportion_of_zeros\": proportion_of_zeros(X)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "9589aaf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:14:45.843295Z",
     "start_time": "2024-12-05T15:14:45.827821Z"
    }
   },
   "source": [
    "def extract_frequency_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts features from activity signal in frequency domain, i.e. calculated\n",
    "    from its Power Spectral Density (PSD).\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: DataFrame with a single row representing features\n",
    "    \"\"\"\n",
    "    X = power_spectral_density(df)\n",
    "    \n",
    "    features = {\n",
    "        \"minimum\": np.min(X),\n",
    "        \"maximum\": np.max(X),\n",
    "        \"mean\": np.mean(X),\n",
    "        \"median\": np.median(X),\n",
    "        \"variance\": np.var(X),\n",
    "        \"kurtosis\": sp.stats.kurtosis(X),\n",
    "        \"skewness\": sp.stats.skew(X),\n",
    "        \"coeff_of_var\": sp.stats.variation(X),\n",
    "        \"iqr\": sp.stats.iqr(X),\n",
    "        \"trimmed_mean\": sp.stats.trim_mean(X, proportiontocut=0.1),\n",
    "        \"entropy\": sp.stats.entropy(X, base=2),\n",
    "        \"spectral_flatness\": spectral_flatness(df)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "e9867a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:14:46.029776Z",
     "start_time": "2024-12-05T15:14:45.998048Z"
    }
   },
   "source": [
    "def extract_features_for_dataframes(dfs: List[List[pd.DataFrame]], is_condition: bool = True, freq: str = \"H\") \\\n",
    "        -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates time and frequency features for given DataFrames. Uses given\n",
    "    frequency for resampling.\n",
    "    \n",
    "    Calculates features separately for:\n",
    "    - full 24hs\n",
    "    - days: [8:00, 21:00)\n",
    "    - nights: [21:00, 8:00)\n",
    "    \n",
    "    :param dfs: list of lists of DataFrames to extract features from; each one has to\n",
    "    have \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency\n",
    "    :returns: dictionary with keys \"full_24h\", \"day\" and \"night\", corresponding\n",
    "    to features from given parts of day\n",
    "    \"\"\"\n",
    "    full_dfs = basic_data_cleaning(dfs)\n",
    "    full_dfs = [[fill_missing_activity(df) for df in patient] for patient in full_dfs]\n",
    "    full_dfs = [[resample(df, freq=freq) for df in patient] for patient in full_dfs]\n",
    "    night_dfs = [[get_day_part(df, part=\"night\") for df in patient] for patient in full_dfs]\n",
    "    day_dfs = [[get_day_part(df, part=\"day\") for df in patient] for patient in full_dfs]\n",
    "\n",
    "    datasets = {}\n",
    "    \n",
    "    \n",
    "    for part, list_of_dfs in [(\"full_24h\", full_dfs), (\"night\", night_dfs), (\"day\", day_dfs)]:\n",
    "        features = []\n",
    "        for patient in range(len(list_of_dfs)):\n",
    "            for day in range(len(list_of_dfs[patient])):\n",
    "                time_features = extract_time_features(list_of_dfs[patient][day])\n",
    "                freq_features = extract_frequency_features(list_of_dfs[patient][day])\n",
    "    \n",
    "                merged_features = pd.merge(\n",
    "                    time_features,\n",
    "                    freq_features,\n",
    "                    left_index=True,\n",
    "                    right_index=True,\n",
    "                    suffixes=(\"_time\", \"_freq\")\n",
    "                )\n",
    "                merged_features['day'] = day + 1\n",
    "                merged_features['patient_id'] = patient + 1\n",
    "                if is_condition:\n",
    "                    merged_features['class'] = 1\n",
    "                else:\n",
    "                    merged_features['class'] = 0\n",
    "                features.append(merged_features)\n",
    "    \n",
    "        datasets[part] = pd.concat(features)\n",
    "        datasets[part].reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return datasets"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "af525f6b",
   "metadata": {},
   "source": [
    "## Hyperaktiv"
   ]
  },
  {
   "cell_type": "code",
   "id": "ea71a0c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:14:49.355941Z",
     "start_time": "2024-12-05T15:14:46.289048Z"
    }
   },
   "source": [
    "path = os.path.join(PROCESSED_DATA_DIR, DAY_WINDOWS_DIR, \"hyperaktiv\")\n",
    "dataset = DatasetWin(dirpath=path, sep=',')\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "16102f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:14:49.413958Z",
     "start_time": "2024-12-05T15:14:49.390139Z"
    }
   },
   "source": [
    "condition[0][0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                timestamp  activity\n",
       "0     2009-02-23 16:00:00       0.0\n",
       "1     2009-02-23 16:01:00     195.0\n",
       "2     2009-02-23 16:02:00     240.0\n",
       "3     2009-02-23 16:03:00     209.0\n",
       "4     2009-02-23 16:04:00     202.0\n",
       "...                   ...       ...\n",
       "1435  2009-02-24 15:55:00     195.0\n",
       "1436  2009-02-24 15:56:00      80.0\n",
       "1437  2009-02-24 15:57:00     104.0\n",
       "1438  2009-02-24 15:58:00      83.0\n",
       "1439  2009-02-24 15:59:00      42.0\n",
       "\n",
       "[1440 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-02-23 16:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-02-23 16:01:00</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-02-23 16:02:00</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-02-23 16:03:00</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-02-23 16:04:00</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2009-02-24 15:55:00</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2009-02-24 15:56:00</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2009-02-24 15:57:00</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2009-02-24 15:58:00</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2009-02-24 15:59:00</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "4109cc01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:15:16.571559Z",
     "start_time": "2024-12-05T15:14:49.509037Z"
    }
   },
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, is_condition=True, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, is_condition=False, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    condition_df = condition_parts_dfs[part]\n",
    "    control_df = control_parts_dfs[part]\n",
    "    max_patient = condition_df['patient_id'].max()\n",
    "    control_df['patient_id'] += max_patient # changing numeration of patients\n",
    "    entire_df = pd.concat([condition_df, control_df], ignore_index=True)\n",
    "    datasets[part] = entire_df"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6270a60c50a6e665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T09:37:50.493610Z",
     "start_time": "2024-11-28T09:37:50.475611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minimum_time</th>\n",
       "      <th>maximum_time</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>variance_time</th>\n",
       "      <th>kurtosis_time</th>\n",
       "      <th>skewness_time</th>\n",
       "      <th>coeff_of_var_time</th>\n",
       "      <th>iqr_time</th>\n",
       "      <th>trimmed_mean_time</th>\n",
       "      <th>...</th>\n",
       "      <th>kurtosis_freq</th>\n",
       "      <th>skewness_freq</th>\n",
       "      <th>coeff_of_var_freq</th>\n",
       "      <th>iqr_freq</th>\n",
       "      <th>trimmed_mean_freq</th>\n",
       "      <th>entropy_freq</th>\n",
       "      <th>spectral_flatness</th>\n",
       "      <th>day</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.450000</td>\n",
       "      <td>215.399994</td>\n",
       "      <td>98.082039</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4445.753906</td>\n",
       "      <td>-1.023036</td>\n",
       "      <td>0.421944</td>\n",
       "      <td>0.653134</td>\n",
       "      <td>98.533337</td>\n",
       "      <td>95.837883</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.102940</td>\n",
       "      <td>0.239344</td>\n",
       "      <td>0.399889</td>\n",
       "      <td>2.704821e+05</td>\n",
       "      <td>3.863297e+05</td>\n",
       "      <td>4.836528</td>\n",
       "      <td>0.915487</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.266670</td>\n",
       "      <td>20.491024</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>1133.641479</td>\n",
       "      <td>3.115266</td>\n",
       "      <td>1.988219</td>\n",
       "      <td>1.578676</td>\n",
       "      <td>31.050000</td>\n",
       "      <td>13.646970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414452</td>\n",
       "      <td>1.392186</td>\n",
       "      <td>1.345802</td>\n",
       "      <td>5.072696e+04</td>\n",
       "      <td>3.355082e+04</td>\n",
       "      <td>3.861883</td>\n",
       "      <td>0.358044</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.599998</td>\n",
       "      <td>15.717948</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>602.977356</td>\n",
       "      <td>2.412652</td>\n",
       "      <td>1.903432</td>\n",
       "      <td>1.500975</td>\n",
       "      <td>10.566666</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534145</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.922332</td>\n",
       "      <td>3.391282e+04</td>\n",
       "      <td>2.106232e+04</td>\n",
       "      <td>4.333512</td>\n",
       "      <td>0.533665</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>403.383331</td>\n",
       "      <td>105.644882</td>\n",
       "      <td>12.183333</td>\n",
       "      <td>20564.833984</td>\n",
       "      <td>-0.578848</td>\n",
       "      <td>0.989674</td>\n",
       "      <td>1.304167</td>\n",
       "      <td>208.750007</td>\n",
       "      <td>88.181816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.892984</td>\n",
       "      <td>0.815363</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>5.788349e+06</td>\n",
       "      <td>3.397530e+06</td>\n",
       "      <td>4.330836</td>\n",
       "      <td>0.577943</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.766666</td>\n",
       "      <td>138.433334</td>\n",
       "      <td>50.897438</td>\n",
       "      <td>38.266666</td>\n",
       "      <td>1330.755493</td>\n",
       "      <td>0.478558</td>\n",
       "      <td>1.065593</td>\n",
       "      <td>0.688608</td>\n",
       "      <td>48.183331</td>\n",
       "      <td>46.496967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141829</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.863809</td>\n",
       "      <td>1.029162e+05</td>\n",
       "      <td>8.174428e+04</td>\n",
       "      <td>4.422207</td>\n",
       "      <td>0.564267</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>119.316666</td>\n",
       "      <td>510.299988</td>\n",
       "      <td>260.858948</td>\n",
       "      <td>229.300003</td>\n",
       "      <td>17234.105469</td>\n",
       "      <td>-0.353035</td>\n",
       "      <td>0.891895</td>\n",
       "      <td>0.483512</td>\n",
       "      <td>140.633331</td>\n",
       "      <td>251.050003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154728</td>\n",
       "      <td>0.842434</td>\n",
       "      <td>0.659194</td>\n",
       "      <td>1.692111e+06</td>\n",
       "      <td>2.098906e+06</td>\n",
       "      <td>4.643049</td>\n",
       "      <td>0.725992</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>79.416664</td>\n",
       "      <td>419.983337</td>\n",
       "      <td>215.976913</td>\n",
       "      <td>216.699997</td>\n",
       "      <td>9484.760742</td>\n",
       "      <td>-0.518492</td>\n",
       "      <td>0.416418</td>\n",
       "      <td>0.433236</td>\n",
       "      <td>142.733337</td>\n",
       "      <td>209.845459</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.159992</td>\n",
       "      <td>0.309771</td>\n",
       "      <td>0.696326</td>\n",
       "      <td>1.098544e+06</td>\n",
       "      <td>9.513142e+05</td>\n",
       "      <td>4.569425</td>\n",
       "      <td>0.672638</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>26.616667</td>\n",
       "      <td>1055.616699</td>\n",
       "      <td>360.837189</td>\n",
       "      <td>323.516663</td>\n",
       "      <td>77397.132812</td>\n",
       "      <td>1.050322</td>\n",
       "      <td>1.152404</td>\n",
       "      <td>0.740747</td>\n",
       "      <td>256.833328</td>\n",
       "      <td>328.059082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.884483</td>\n",
       "      <td>0.799677</td>\n",
       "      <td>1.081417</td>\n",
       "      <td>1.201404e+07</td>\n",
       "      <td>5.903548e+06</td>\n",
       "      <td>4.095445</td>\n",
       "      <td>0.379739</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>622.066650</td>\n",
       "      <td>160.816650</td>\n",
       "      <td>106.333336</td>\n",
       "      <td>39549.644531</td>\n",
       "      <td>0.284912</td>\n",
       "      <td>1.184161</td>\n",
       "      <td>1.188117</td>\n",
       "      <td>165.816674</td>\n",
       "      <td>133.504547</td>\n",
       "      <td>...</td>\n",
       "      <td>1.154687</td>\n",
       "      <td>1.429178</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>1.225944e+06</td>\n",
       "      <td>1.117923e+06</td>\n",
       "      <td>4.296974</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>127.333336</td>\n",
       "      <td>366.399994</td>\n",
       "      <td>217.383331</td>\n",
       "      <td>212.333328</td>\n",
       "      <td>5053.597656</td>\n",
       "      <td>-0.391095</td>\n",
       "      <td>0.667669</td>\n",
       "      <td>0.314190</td>\n",
       "      <td>92.333328</td>\n",
       "      <td>212.022720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186540</td>\n",
       "      <td>1.110178</td>\n",
       "      <td>0.707044</td>\n",
       "      <td>3.035579e+05</td>\n",
       "      <td>3.813853e+05</td>\n",
       "      <td>4.622574</td>\n",
       "      <td>0.763820</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     minimum_time  maximum_time   mean_time  median_time  variance_time  \\\n",
       "0        5.450000    215.399994   98.082039    85.000000    4445.753906   \n",
       "1        0.000000    116.266670   20.491024     4.550000    1133.641479   \n",
       "2        0.000000     82.599998   15.717948     3.916667     602.977356   \n",
       "3        0.000000    403.383331  105.644882    12.183333   20564.833984   \n",
       "4       11.766666    138.433334   50.897438    38.266666    1330.755493   \n",
       "..            ...           ...         ...          ...            ...   \n",
       "542    119.316666    510.299988  260.858948   229.300003   17234.105469   \n",
       "543     79.416664    419.983337  215.976913   216.699997    9484.760742   \n",
       "544     26.616667   1055.616699  360.837189   323.516663   77397.132812   \n",
       "545      0.000000    622.066650  160.816650   106.333336   39549.644531   \n",
       "546    127.333336    366.399994  217.383331   212.333328    5053.597656   \n",
       "\n",
       "     kurtosis_time  skewness_time  coeff_of_var_time    iqr_time  \\\n",
       "0        -1.023036       0.421944           0.653134   98.533337   \n",
       "1         3.115266       1.988219           1.578676   31.050000   \n",
       "2         2.412652       1.903432           1.500975   10.566666   \n",
       "3        -0.578848       0.989674           1.304167  208.750007   \n",
       "4         0.478558       1.065593           0.688608   48.183331   \n",
       "..             ...            ...                ...         ...   \n",
       "542      -0.353035       0.891895           0.483512  140.633331   \n",
       "543      -0.518492       0.416418           0.433236  142.733337   \n",
       "544       1.050322       1.152404           0.740747  256.833328   \n",
       "545       0.284912       1.184161           1.188117  165.816674   \n",
       "546      -0.391095       0.667669           0.314190   92.333328   \n",
       "\n",
       "     trimmed_mean_time  ...  kurtosis_freq  skewness_freq  coeff_of_var_freq  \\\n",
       "0            95.837883  ...      -1.102940       0.239344           0.399889   \n",
       "1            13.646970  ...       0.414452       1.392186           1.345802   \n",
       "2            11.066667  ...      -0.534145       0.809441           0.922332   \n",
       "3            88.181816  ...      -0.892984       0.815363           0.946616   \n",
       "4            46.496967  ...      -0.141829       0.944444           0.863809   \n",
       "..                 ...  ...            ...            ...                ...   \n",
       "542         251.050003  ...      -0.154728       0.842434           0.659194   \n",
       "543         209.845459  ...      -1.159992       0.309771           0.696326   \n",
       "544         328.059082  ...      -0.884483       0.799677           1.081417   \n",
       "545         133.504547  ...       1.154687       1.429178           0.999763   \n",
       "546         212.022720  ...       0.186540       1.110178           0.707044   \n",
       "\n",
       "         iqr_freq  trimmed_mean_freq  entropy_freq  spectral_flatness  day  \\\n",
       "0    2.704821e+05       3.863297e+05      4.836528           0.915487    1   \n",
       "1    5.072696e+04       3.355082e+04      3.861883           0.358044    2   \n",
       "2    3.391282e+04       2.106232e+04      4.333512           0.533665    3   \n",
       "3    5.788349e+06       3.397530e+06      4.330836           0.577943    4   \n",
       "4    1.029162e+05       8.174428e+04      4.422207           0.564267    5   \n",
       "..            ...                ...           ...                ...  ...   \n",
       "542  1.692111e+06       2.098906e+06      4.643049           0.725992    2   \n",
       "543  1.098544e+06       9.513142e+05      4.569425           0.672638    3   \n",
       "544  1.201404e+07       5.903548e+06      4.095445           0.379739    4   \n",
       "545  1.225944e+06       1.117923e+06      4.296974           0.411765    5   \n",
       "546  3.035579e+05       3.813853e+05      4.622574           0.763820    6   \n",
       "\n",
       "     patient_id  class  \n",
       "0             1      1  \n",
       "1             1      1  \n",
       "2             1      1  \n",
       "3             1      1  \n",
       "4             1      1  \n",
       "..          ...    ...  \n",
       "542          85      0  \n",
       "543          85      0  \n",
       "544          85      0  \n",
       "545          85      0  \n",
       "546          85      0  \n",
       "\n",
       "[547 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3b78fed5d5e278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T09:38:36.920092Z",
     "start_time": "2024-11-28T09:38:36.889141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minimum_time</th>\n",
       "      <th>maximum_time</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>variance_time</th>\n",
       "      <th>kurtosis_time</th>\n",
       "      <th>skewness_time</th>\n",
       "      <th>coeff_of_var_time</th>\n",
       "      <th>iqr_time</th>\n",
       "      <th>trimmed_mean_time</th>\n",
       "      <th>...</th>\n",
       "      <th>kurtosis_freq</th>\n",
       "      <th>skewness_freq</th>\n",
       "      <th>coeff_of_var_freq</th>\n",
       "      <th>iqr_freq</th>\n",
       "      <th>trimmed_mean_freq</th>\n",
       "      <th>entropy_freq</th>\n",
       "      <th>spectral_flatness</th>\n",
       "      <th>day</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.450000</td>\n",
       "      <td>215.399994</td>\n",
       "      <td>98.082039</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4445.753906</td>\n",
       "      <td>-1.023036</td>\n",
       "      <td>0.421944</td>\n",
       "      <td>0.653134</td>\n",
       "      <td>98.533337</td>\n",
       "      <td>95.837883</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.102940</td>\n",
       "      <td>0.239344</td>\n",
       "      <td>0.399889</td>\n",
       "      <td>2.704821e+05</td>\n",
       "      <td>3.863297e+05</td>\n",
       "      <td>4.836528</td>\n",
       "      <td>0.915487</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.266670</td>\n",
       "      <td>20.491024</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>1133.641479</td>\n",
       "      <td>3.115266</td>\n",
       "      <td>1.988219</td>\n",
       "      <td>1.578676</td>\n",
       "      <td>31.050000</td>\n",
       "      <td>13.646970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414452</td>\n",
       "      <td>1.392186</td>\n",
       "      <td>1.345802</td>\n",
       "      <td>5.072696e+04</td>\n",
       "      <td>3.355082e+04</td>\n",
       "      <td>3.861883</td>\n",
       "      <td>0.358044</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.599998</td>\n",
       "      <td>15.717948</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>602.977356</td>\n",
       "      <td>2.412652</td>\n",
       "      <td>1.903432</td>\n",
       "      <td>1.500975</td>\n",
       "      <td>10.566666</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534145</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.922332</td>\n",
       "      <td>3.391282e+04</td>\n",
       "      <td>2.106232e+04</td>\n",
       "      <td>4.333512</td>\n",
       "      <td>0.533665</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>403.383331</td>\n",
       "      <td>105.644882</td>\n",
       "      <td>12.183333</td>\n",
       "      <td>20564.833984</td>\n",
       "      <td>-0.578848</td>\n",
       "      <td>0.989674</td>\n",
       "      <td>1.304167</td>\n",
       "      <td>208.750007</td>\n",
       "      <td>88.181816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.892984</td>\n",
       "      <td>0.815363</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>5.788349e+06</td>\n",
       "      <td>3.397530e+06</td>\n",
       "      <td>4.330836</td>\n",
       "      <td>0.577943</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.766666</td>\n",
       "      <td>138.433334</td>\n",
       "      <td>50.897438</td>\n",
       "      <td>38.266666</td>\n",
       "      <td>1330.755493</td>\n",
       "      <td>0.478558</td>\n",
       "      <td>1.065593</td>\n",
       "      <td>0.688608</td>\n",
       "      <td>48.183331</td>\n",
       "      <td>46.496967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141829</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.863809</td>\n",
       "      <td>1.029162e+05</td>\n",
       "      <td>8.174428e+04</td>\n",
       "      <td>4.422207</td>\n",
       "      <td>0.564267</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>119.316666</td>\n",
       "      <td>510.299988</td>\n",
       "      <td>260.858948</td>\n",
       "      <td>229.300003</td>\n",
       "      <td>17234.105469</td>\n",
       "      <td>-0.353035</td>\n",
       "      <td>0.891895</td>\n",
       "      <td>0.483512</td>\n",
       "      <td>140.633331</td>\n",
       "      <td>251.050003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154728</td>\n",
       "      <td>0.842434</td>\n",
       "      <td>0.659194</td>\n",
       "      <td>1.692111e+06</td>\n",
       "      <td>2.098906e+06</td>\n",
       "      <td>4.643049</td>\n",
       "      <td>0.725992</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>79.416664</td>\n",
       "      <td>419.983337</td>\n",
       "      <td>215.976913</td>\n",
       "      <td>216.699997</td>\n",
       "      <td>9484.760742</td>\n",
       "      <td>-0.518492</td>\n",
       "      <td>0.416418</td>\n",
       "      <td>0.433236</td>\n",
       "      <td>142.733337</td>\n",
       "      <td>209.845459</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.159992</td>\n",
       "      <td>0.309771</td>\n",
       "      <td>0.696326</td>\n",
       "      <td>1.098544e+06</td>\n",
       "      <td>9.513142e+05</td>\n",
       "      <td>4.569425</td>\n",
       "      <td>0.672638</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>26.616667</td>\n",
       "      <td>1055.616699</td>\n",
       "      <td>360.837189</td>\n",
       "      <td>323.516663</td>\n",
       "      <td>77397.132812</td>\n",
       "      <td>1.050322</td>\n",
       "      <td>1.152404</td>\n",
       "      <td>0.740747</td>\n",
       "      <td>256.833328</td>\n",
       "      <td>328.059082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.884483</td>\n",
       "      <td>0.799677</td>\n",
       "      <td>1.081417</td>\n",
       "      <td>1.201404e+07</td>\n",
       "      <td>5.903548e+06</td>\n",
       "      <td>4.095445</td>\n",
       "      <td>0.379739</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>622.066650</td>\n",
       "      <td>160.816650</td>\n",
       "      <td>106.333336</td>\n",
       "      <td>39549.644531</td>\n",
       "      <td>0.284912</td>\n",
       "      <td>1.184161</td>\n",
       "      <td>1.188117</td>\n",
       "      <td>165.816674</td>\n",
       "      <td>133.504547</td>\n",
       "      <td>...</td>\n",
       "      <td>1.154687</td>\n",
       "      <td>1.429178</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>1.225944e+06</td>\n",
       "      <td>1.117923e+06</td>\n",
       "      <td>4.296974</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>127.333336</td>\n",
       "      <td>366.399994</td>\n",
       "      <td>217.383331</td>\n",
       "      <td>212.333328</td>\n",
       "      <td>5053.597656</td>\n",
       "      <td>-0.391095</td>\n",
       "      <td>0.667669</td>\n",
       "      <td>0.314190</td>\n",
       "      <td>92.333328</td>\n",
       "      <td>212.022720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186540</td>\n",
       "      <td>1.110178</td>\n",
       "      <td>0.707044</td>\n",
       "      <td>3.035579e+05</td>\n",
       "      <td>3.813853e+05</td>\n",
       "      <td>4.622574</td>\n",
       "      <td>0.763820</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     minimum_time  maximum_time   mean_time  median_time  variance_time  \\\n",
       "0        5.450000    215.399994   98.082039    85.000000    4445.753906   \n",
       "1        0.000000    116.266670   20.491024     4.550000    1133.641479   \n",
       "2        0.000000     82.599998   15.717948     3.916667     602.977356   \n",
       "3        0.000000    403.383331  105.644882    12.183333   20564.833984   \n",
       "4       11.766666    138.433334   50.897438    38.266666    1330.755493   \n",
       "..            ...           ...         ...          ...            ...   \n",
       "542    119.316666    510.299988  260.858948   229.300003   17234.105469   \n",
       "543     79.416664    419.983337  215.976913   216.699997    9484.760742   \n",
       "544     26.616667   1055.616699  360.837189   323.516663   77397.132812   \n",
       "545      0.000000    622.066650  160.816650   106.333336   39549.644531   \n",
       "546    127.333336    366.399994  217.383331   212.333328    5053.597656   \n",
       "\n",
       "     kurtosis_time  skewness_time  coeff_of_var_time    iqr_time  \\\n",
       "0        -1.023036       0.421944           0.653134   98.533337   \n",
       "1         3.115266       1.988219           1.578676   31.050000   \n",
       "2         2.412652       1.903432           1.500975   10.566666   \n",
       "3        -0.578848       0.989674           1.304167  208.750007   \n",
       "4         0.478558       1.065593           0.688608   48.183331   \n",
       "..             ...            ...                ...         ...   \n",
       "542      -0.353035       0.891895           0.483512  140.633331   \n",
       "543      -0.518492       0.416418           0.433236  142.733337   \n",
       "544       1.050322       1.152404           0.740747  256.833328   \n",
       "545       0.284912       1.184161           1.188117  165.816674   \n",
       "546      -0.391095       0.667669           0.314190   92.333328   \n",
       "\n",
       "     trimmed_mean_time  ...  kurtosis_freq  skewness_freq  coeff_of_var_freq  \\\n",
       "0            95.837883  ...      -1.102940       0.239344           0.399889   \n",
       "1            13.646970  ...       0.414452       1.392186           1.345802   \n",
       "2            11.066667  ...      -0.534145       0.809441           0.922332   \n",
       "3            88.181816  ...      -0.892984       0.815363           0.946616   \n",
       "4            46.496967  ...      -0.141829       0.944444           0.863809   \n",
       "..                 ...  ...            ...            ...                ...   \n",
       "542         251.050003  ...      -0.154728       0.842434           0.659194   \n",
       "543         209.845459  ...      -1.159992       0.309771           0.696326   \n",
       "544         328.059082  ...      -0.884483       0.799677           1.081417   \n",
       "545         133.504547  ...       1.154687       1.429178           0.999763   \n",
       "546         212.022720  ...       0.186540       1.110178           0.707044   \n",
       "\n",
       "         iqr_freq  trimmed_mean_freq  entropy_freq  spectral_flatness  day  \\\n",
       "0    2.704821e+05       3.863297e+05      4.836528           0.915487    1   \n",
       "1    5.072696e+04       3.355082e+04      3.861883           0.358044    2   \n",
       "2    3.391282e+04       2.106232e+04      4.333512           0.533665    3   \n",
       "3    5.788349e+06       3.397530e+06      4.330836           0.577943    4   \n",
       "4    1.029162e+05       8.174428e+04      4.422207           0.564267    5   \n",
       "..            ...                ...           ...                ...  ...   \n",
       "542  1.692111e+06       2.098906e+06      4.643049           0.725992    2   \n",
       "543  1.098544e+06       9.513142e+05      4.569425           0.672638    3   \n",
       "544  1.201404e+07       5.903548e+06      4.095445           0.379739    4   \n",
       "545  1.225944e+06       1.117923e+06      4.296974           0.411765    5   \n",
       "546  3.035579e+05       3.813853e+05      4.622574           0.763820    6   \n",
       "\n",
       "     patient_id  class  \n",
       "0             1      1  \n",
       "1             1      1  \n",
       "2             1      1  \n",
       "3             1      1  \n",
       "4             1      1  \n",
       "..          ...    ...  \n",
       "542          85      0  \n",
       "543          85      0  \n",
       "544          85      0  \n",
       "545          85      0  \n",
       "546          85      0  \n",
       "\n",
       "[547 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4932f103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T09:38:45.200814Z",
     "start_time": "2024-11-28T09:38:45.165814Z"
    }
   },
   "outputs": [],
   "source": [
    "# save manual features\n",
    "# os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "# for part, df in datasets.items():\n",
    "#     filename = f\"{HYPERAKTIV_PREFIX}_window_{part}.csv\"\n",
    "#     filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "#     df.to_csv(filepath, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195102c",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff79d6",
   "metadata": {},
   "source": [
    "## Classifiers, parameters, constants"
   ]
  },
  {
   "cell_type": "code",
   "id": "00c0242a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:15:47.310594Z",
     "start_time": "2024-12-05T15:15:47.290176Z"
    }
   },
   "source": [
    "classifiers = {\n",
    "    \"LR\": LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        random_state=0,\n",
    "        solver=\"saga\",\n",
    "        max_iter=5000\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        kernel=\"rbf\",\n",
    "        cache_size=512\n",
    "    ),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        criterion=\"entropy\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    \"LR\": {\n",
    "        \"C\": [0.001, 0.01, 0.1, 0.5, 1, 2, 5, 10, 25, 50, 100, 500, 1000],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"l1_ratio\": [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\n",
    "                     0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"C\": np.logspace(10e-3, 10e3, num=50),\n",
    "        \"gamma\": np.logspace(10e-3, 10e3, num=50),\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "44383487",
   "metadata": {},
   "source": [
    "## Hyperaktiv Classification"
   ]
  },
  {
   "cell_type": "code",
   "id": "299853bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:15:52.265823Z",
     "start_time": "2024-12-05T15:15:52.247807Z"
    }
   },
   "source": [
    "dataset = HYPERAKTIV_PREFIX"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "518e18e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:16:15.295557Z",
     "start_time": "2024-12-05T15:16:15.247696Z"
    }
   },
   "source": [
    "# create dictionary with data split for night/day/all\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    filename = f\"{dataset}_window_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    datasets[part] = pd.read_csv(filepath, header=0).dropna()\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "34de5aff627f54cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:33:57.902821Z",
     "start_time": "2024-12-05T15:33:57.889203Z"
    }
   },
   "source": [
    "# X = pd.concat([datasets['full_24h'].iloc[:25, :], datasets['full_24h'].iloc[-25:, :]])\n",
    "# X = X.reset_index(drop=True)\n",
    "# \n",
    "# y = datasets[\"full_24h\"]['class']\n",
    "# y = pd.concat([y[:25], y[-25:]])\n",
    "# y = y.reset_index(drop=True)\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T15:34:02.559209Z",
     "start_time": "2024-12-05T15:34:02.538835Z"
    }
   },
   "cell_type": "code",
   "source": "datasets[\"day\"].info()",
   "id": "84f624c870936cb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 546 entries, 0 to 546\n",
      "Data columns (total 27 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   minimum_time         546 non-null    float64\n",
      " 1   maximum_time         546 non-null    float64\n",
      " 2   mean_time            546 non-null    float64\n",
      " 3   median_time          546 non-null    float64\n",
      " 4   variance_time        546 non-null    float64\n",
      " 5   kurtosis_time        546 non-null    float64\n",
      " 6   skewness_time        546 non-null    float64\n",
      " 7   coeff_of_var_time    546 non-null    float64\n",
      " 8   iqr_time             546 non-null    float64\n",
      " 9   trimmed_mean_time    546 non-null    float64\n",
      " 10  entropy_time         546 non-null    float64\n",
      " 11  proportion_of_zeros  546 non-null    float64\n",
      " 12  minimum_freq         546 non-null    float64\n",
      " 13  maximum_freq         546 non-null    float64\n",
      " 14  mean_freq            546 non-null    float64\n",
      " 15  median_freq          546 non-null    float64\n",
      " 16  variance_freq        546 non-null    float64\n",
      " 17  kurtosis_freq        546 non-null    float64\n",
      " 18  skewness_freq        546 non-null    float64\n",
      " 19  coeff_of_var_freq    546 non-null    float64\n",
      " 20  iqr_freq             546 non-null    float64\n",
      " 21  trimmed_mean_freq    546 non-null    float64\n",
      " 22  entropy_freq         546 non-null    float64\n",
      " 23  spectral_flatness    546 non-null    float64\n",
      " 24  day                  546 non-null    int64  \n",
      " 25  patient_id           546 non-null    int64  \n",
      " 26  class                546 non-null    int64  \n",
      "dtypes: float64(24), int64(3)\n",
      "memory usage: 119.4 KB\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-05T16:15:02.368461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_directory = os.path.join(\".\", MAIN_RESULTS_DIR, DAY_WINDOWS_DIR, \"hyperactiv\")\n",
    "predictions_directory = os.path.join('.', MAIN_RESULTS_DIR, DAY_WINDOWS_DIR, \"hyperactiv\", \"predictions\")\n",
    "os.makedirs(results_directory, exist_ok=True)\n",
    "os.makedirs(predictions_directory, exist_ok=True)\n",
    "predictions = pd.DataFrame(columns=['fold', 'classifier', 'predicted_class', 'actual_class', 'patient_id'])\n",
    "\n",
    "for part in [\"night\", \"full_24h\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    X = datasets[part]\n",
    "    y = datasets[part]['class']\n",
    "    print(len(X))\n",
    "    info = X.iloc[:, -3:]\n",
    "    group_kfold = GroupKFold(n_splits=2)\n",
    "    fold_num = 0\n",
    "    all_predictions = pd.DataFrame()\n",
    "    \n",
    "    for train_idx, test_idx in group_kfold.split(X, y, groups=X['patient_id']):\n",
    "        fold_num += 1 \n",
    "        X = X.iloc[:, :-3]\n",
    "        print(\"fold: \", fold_num)\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "        X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.005)\n",
    "        X_train, X_test = standardize(X_train, X_test)\n",
    "    \n",
    "        for clf_type in [\"LR\", \"SVM\", \"RF\"]: \n",
    "            print(f\"    {clf_type}\")\n",
    "            \n",
    "            test_scores = []\n",
    "            \n",
    "            model = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=list(GroupKFold(n_splits=3).split(X_train, y_train, info.iloc[train_idx][\"patient_id\"]))\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            metrics = calculate_metrics(model, X_test, y_test)\n",
    "            # print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "    \n",
    "            # Save individual fold metrics\n",
    "            pd.DataFrame.from_records(test_scores).to_csv(\n",
    "                os.path.join(results_directory, f\"test_scores_{part}_fold_{clf_type}\"),\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            predictions_dict = {\n",
    "                \"fold\": [fold_num] * len(y_test),\n",
    "                'classifier': [clf_type] * len(y_test),\n",
    "                'predicted_class': y_pred,\n",
    "                'actual_class': y_test,\n",
    "                \"patient_id\": info.iloc[test_idx][\"patient_id\"].to_list()\n",
    "            }\n",
    "            predictions = pd.DataFrame.from_dict(predictions_dict)\n",
    "            all_predictions = pd.concat([all_predictions, predictions])\n",
    "    \n",
    "            # Compute and save final scores for the fold\n",
    "            final_scores = calculate_metrics_statistics(test_scores)\n",
    "            df = pd.DataFrame([(key,) + values for key, values in final_scores.items()],\n",
    "                              columns=['Index', 'Mean', 'Stddev']).set_index('Index')\n",
    "            df.to_csv(\n",
    "                os.path.join(results_directory, f\"final_scores_{part}_fold\"),\n",
    "            )\n",
    "        \n",
    "            for metric, (mean, stddev) in final_scores.items():\n",
    "                print(f\"      {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "            print()\n",
    "        \n",
    "    all_predictions.to_csv(\n",
    "    os.path.join(predictions_directory, f\"predictions_{part}.csv\"),\n",
    "    index=False\n",
    "    )\n"
   ],
   "id": "56f05da8d16a7c69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART: night\n",
      "545\n",
      "fold:  1\n",
      "    LR\n",
      "      accuracy: 0.4559 +- 0.0000\n",
      "      balanced_accuracy: 0.4544 +- 0.0000\n",
      "      f1: 0.5099 +- 0.0000\n",
      "      precision: 0.4695 +- 0.0000\n",
      "      recall: 0.5580 +- 0.0000\n",
      "      specificity: 0.3507 +- 0.0000\n",
      "      ROC_AUC: 0.4544 +- 0.0000\n",
      "      MCC: -0.0933 +- 0.0000\n",
      "\n",
      "    SVM\n",
      "      accuracy: 0.5074 +- 0.0000\n",
      "      balanced_accuracy: 0.5000 +- 0.0000\n",
      "      f1: 0.6732 +- 0.0000\n",
      "      precision: 0.5074 +- 0.0000\n",
      "      recall: 1.0000 +- 0.0000\n",
      "      specificity: 0.0000 +- 0.0000\n",
      "      ROC_AUC: 0.5000 +- 0.0000\n",
      "      MCC: 0.0000 +- 0.0000\n",
      "\n",
      "    RF\n",
      "      accuracy: 0.4816 +- 0.0000\n",
      "      balanced_accuracy: 0.4818 +- 0.0000\n",
      "      f1: 0.4797 +- 0.0000\n",
      "      precision: 0.4887 +- 0.0000\n",
      "      recall: 0.4710 +- 0.0000\n",
      "      specificity: 0.4925 +- 0.0000\n",
      "      ROC_AUC: 0.4818 +- 0.0000\n",
      "      MCC: -0.0365 +- 0.0000\n",
      "\n",
      "fold:  2\n",
      "    LR\n",
      "      accuracy: 0.4212 +- 0.0000\n",
      "      balanced_accuracy: 0.4205 +- 0.0000\n",
      "      f1: 0.4476 +- 0.0000\n",
      "      precision: 0.4354 +- 0.0000\n",
      "      recall: 0.4604 +- 0.0000\n",
      "      specificity: 0.3806 +- 0.0000\n",
      "      ROC_AUC: 0.4205 +- 0.0000\n",
      "      MCC: -0.1594 +- 0.0000\n",
      "\n",
      "    SVM\n",
      "      accuracy: 0.4835 +- 0.0000\n",
      "      balanced_accuracy: 0.4810 +- 0.0000\n",
      "      f1: 0.5495 +- 0.0000\n",
      "      precision: 0.4943 +- 0.0000\n",
      "      recall: 0.6187 +- 0.0000\n",
      "      specificity: 0.3433 +- 0.0000\n",
      "      ROC_AUC: 0.4810 +- 0.0000\n",
      "      MCC: -0.0395 +- 0.0000\n",
      "\n",
      "    RF\n",
      "      accuracy: 0.4982 +- 0.0000\n",
      "      balanced_accuracy: 0.4978 +- 0.0000\n",
      "      f1: 0.5125 +- 0.0000\n",
      "      precision: 0.5070 +- 0.0000\n",
      "      recall: 0.5180 +- 0.0000\n",
      "      specificity: 0.4776 +- 0.0000\n",
      "      ROC_AUC: 0.4978 +- 0.0000\n",
      "      MCC: -0.0044 +- 0.0000\n",
      "\n",
      "PART: full_24h\n",
      "547\n",
      "fold:  1\n",
      "    LR\n",
      "      accuracy: 0.4579 +- 0.0000\n",
      "      balanced_accuracy: 0.4534 +- 0.0000\n",
      "      f1: 0.5099 +- 0.0000\n",
      "      precision: 0.4873 +- 0.0000\n",
      "      recall: 0.5347 +- 0.0000\n",
      "      specificity: 0.3721 +- 0.0000\n",
      "      ROC_AUC: 0.4534 +- 0.0000\n",
      "      MCC: -0.0942 +- 0.0000\n",
      "\n",
      "    SVM\n",
      "      accuracy: 0.4066 +- 0.0000\n",
      "      balanced_accuracy: 0.4177 +- 0.0000\n",
      "      f1: 0.2768 +- 0.0000\n",
      "      precision: 0.3875 +- 0.0000\n",
      "      recall: 0.2153 +- 0.0000\n",
      "      specificity: 0.6202 +- 0.0000\n",
      "      ROC_AUC: 0.4177 +- 0.0000\n",
      "      MCC: -0.1805 +- 0.0000\n",
      "\n",
      "    RF\n",
      "      accuracy: 0.4579 +- 0.0000\n",
      "      balanced_accuracy: 0.4538 +- 0.0000\n",
      "      f1: 0.5067 +- 0.0000\n",
      "      precision: 0.4872 +- 0.0000\n",
      "      recall: 0.5278 +- 0.0000\n",
      "      specificity: 0.3798 +- 0.0000\n",
      "      ROC_AUC: 0.4538 +- 0.0000\n",
      "      MCC: -0.0932 +- 0.0000\n",
      "\n",
      "fold:  2\n",
      "    LR\n",
      "      accuracy: 0.3650 +- 0.0000\n",
      "      balanced_accuracy: 0.3674 +- 0.0000\n",
      "      f1: 0.4082 +- 0.0000\n",
      "      precision: 0.3727 +- 0.0000\n",
      "      recall: 0.4511 +- 0.0000\n",
      "      specificity: 0.2837 +- 0.0000\n",
      "      ROC_AUC: 0.3674 +- 0.0000\n",
      "      MCC: -0.2692 +- 0.0000\n",
      "\n",
      "    SVM\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8e676172",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "id": "c879fd99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T16:12:06.686965Z",
     "start_time": "2024-12-05T16:12:06.505346Z"
    }
   },
   "source": [
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    predictions = pd.read_csv(os.path.join(predictions_directory, f\"predictions_{part}.csv\"))\n",
    "    #print(predictions)\n",
    "\n",
    "    grouped = predictions.groupby(['patient_id', 'classifier'])\n",
    "\n",
    "    most_common_class = (\n",
    "        grouped['predicted_class']\n",
    "        .apply(lambda x: x.mode()[0]) \n",
    "        .reset_index(name='final_predicted_class')\n",
    "    )\n",
    "\n",
    "    final_results = pd.merge(\n",
    "        most_common_class,\n",
    "        predictions[['patient_id', 'actual_class']].drop_duplicates(),\n",
    "        on='patient_id'\n",
    "    )\n",
    "\n",
    "    #print(final_results)\n",
    "\n",
    "    final_results.to_csv(\n",
    "        os.path.join(predictions_directory, f\"final_predictions_{part}.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    voting_metrics = (\n",
    "    final_results.groupby('classifier')\n",
    "    .apply(lambda group: pd.Series(\n",
    "        calculate_metrics_from_df(group['actual_class'], group['final_predicted_class'])\n",
    "    ))\n",
    "    .reset_index()\n",
    "    )\n",
    "\n",
    "    print(voting_metrics)\n",
    "    \n",
    "    voting_metrics.to_csv(\n",
    "    os.path.join(predictions_directory, f\"voting_scores_{part}.csv\"),\n",
    "    index=False\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART: full_24h\n",
      "  classifier  accuracy  balanced_accuracy        f1  precision    recall  \\\n",
      "0         RF  0.348837           0.348485  0.363636   0.363636  0.363636   \n",
      "\n",
      "   specificity   ROC_AUC      MCC  \n",
      "0     0.333333  0.348485 -0.30303  \n",
      "PART: night\n",
      "  classifier  accuracy  balanced_accuracy        f1  precision    recall  \\\n",
      "0         RF  0.465116           0.467391  0.465116        0.5  0.434783   \n",
      "\n",
      "   specificity   ROC_AUC       MCC  \n",
      "0          0.5  0.467391 -0.065217  \n",
      "PART: day\n",
      "  classifier  accuracy  balanced_accuracy        f1  precision    recall  \\\n",
      "0         RF  0.285714           0.283753  0.318182   0.333333  0.304348   \n",
      "\n",
      "   specificity   ROC_AUC       MCC  \n",
      "0     0.263158  0.283753 -0.430528  \n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "42b3064f",
   "metadata": {},
   "source": [
    "## Depresjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd4d76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:49:36.814427Z",
     "start_time": "2024-11-28T11:49:35.303681Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.path.join(PROCESSED_DATA_DIR, DAY_WINDOWS_DIR, \"depresjon\")\n",
    "dataset = DatasetWin(dirpath=path, sep=',')\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c2f0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:49:36.846156Z",
     "start_time": "2024-11-28T11:49:36.824432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-05-07 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-05-07 12:01:00</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-05-07 12:02:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-05-07 12:03:00</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-07 12:04:00</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2003-05-08 11:55:00</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2003-05-08 11:56:00</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2003-05-08 11:57:00</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2003-05-08 11:58:00</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2003-05-08 11:59:00</td>\n",
       "      <td>296.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp  activity\n",
       "0     2003-05-07 12:00:00       0.0\n",
       "1     2003-05-07 12:01:00     143.0\n",
       "2     2003-05-07 12:02:00       0.0\n",
       "3     2003-05-07 12:03:00      20.0\n",
       "4     2003-05-07 12:04:00     166.0\n",
       "...                   ...       ...\n",
       "1435  2003-05-08 11:55:00     259.0\n",
       "1436  2003-05-08 11:56:00     190.0\n",
       "1437  2003-05-08 11:57:00     306.0\n",
       "1438  2003-05-08 11:58:00      91.0\n",
       "1439  2003-05-08 11:59:00     296.0\n",
       "\n",
       "[1440 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6a20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:50:05.337680Z",
     "start_time": "2024-11-28T11:49:40.264276Z"
    }
   },
   "outputs": [],
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    condition_df = condition_parts_dfs[part]\n",
    "    control_df = control_parts_dfs[part]\n",
    "    max_patient = condition_df['patient_id'].max()\n",
    "    control_df['patient_id'] += max_patient # changing numeration of patients\n",
    "    entire_df = pd.concat([condition_df, control_df], ignore_index=True)\n",
    "    datasets[part] = entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b621c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:50:39.637700Z",
     "start_time": "2024-11-28T11:50:39.578547Z"
    }
   },
   "outputs": [],
   "source": [
    "for part, df in datasets.items():\n",
    "    filename = f\"{DEPRESJON_PREFIX}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e4594c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:50:52.039758Z",
     "start_time": "2024-11-28T11:50:52.015758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minimum_time</th>\n",
       "      <th>maximum_time</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>variance_time</th>\n",
       "      <th>kurtosis_time</th>\n",
       "      <th>skewness_time</th>\n",
       "      <th>coeff_of_var_time</th>\n",
       "      <th>iqr_time</th>\n",
       "      <th>trimmed_mean_time</th>\n",
       "      <th>...</th>\n",
       "      <th>kurtosis_freq</th>\n",
       "      <th>skewness_freq</th>\n",
       "      <th>coeff_of_var_freq</th>\n",
       "      <th>iqr_freq</th>\n",
       "      <th>trimmed_mean_freq</th>\n",
       "      <th>entropy_freq</th>\n",
       "      <th>spectral_flatness</th>\n",
       "      <th>day</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>395.649994</td>\n",
       "      <td>131.482635</td>\n",
       "      <td>105.699997</td>\n",
       "      <td>16655.847656</td>\n",
       "      <td>-0.920655</td>\n",
       "      <td>0.638463</td>\n",
       "      <td>0.960889</td>\n",
       "      <td>212.062506</td>\n",
       "      <td>120.149170</td>\n",
       "      <td>...</td>\n",
       "      <td>4.867227</td>\n",
       "      <td>2.483317</td>\n",
       "      <td>2.018346</td>\n",
       "      <td>2.211316e+05</td>\n",
       "      <td>5.500495e+05</td>\n",
       "      <td>3.240957</td>\n",
       "      <td>0.281053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>569.866638</td>\n",
       "      <td>172.020142</td>\n",
       "      <td>84.541672</td>\n",
       "      <td>33375.023438</td>\n",
       "      <td>-0.561575</td>\n",
       "      <td>0.833602</td>\n",
       "      <td>1.039656</td>\n",
       "      <td>304.258337</td>\n",
       "      <td>150.076660</td>\n",
       "      <td>...</td>\n",
       "      <td>4.082882</td>\n",
       "      <td>2.325901</td>\n",
       "      <td>1.870382</td>\n",
       "      <td>1.386454e+06</td>\n",
       "      <td>1.227904e+06</td>\n",
       "      <td>3.344774</td>\n",
       "      <td>0.230570</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>505.100006</td>\n",
       "      <td>150.905563</td>\n",
       "      <td>80.291664</td>\n",
       "      <td>27618.832031</td>\n",
       "      <td>-0.605859</td>\n",
       "      <td>0.969403</td>\n",
       "      <td>1.078092</td>\n",
       "      <td>218.149999</td>\n",
       "      <td>132.926666</td>\n",
       "      <td>...</td>\n",
       "      <td>4.611042</td>\n",
       "      <td>2.451845</td>\n",
       "      <td>2.050603</td>\n",
       "      <td>5.640596e+05</td>\n",
       "      <td>6.595294e+05</td>\n",
       "      <td>3.154835</td>\n",
       "      <td>0.232096</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.950000</td>\n",
       "      <td>362.500000</td>\n",
       "      <td>121.906250</td>\n",
       "      <td>98.341667</td>\n",
       "      <td>12383.744141</td>\n",
       "      <td>-0.782771</td>\n",
       "      <td>0.595389</td>\n",
       "      <td>0.893631</td>\n",
       "      <td>188.479172</td>\n",
       "      <td>111.311668</td>\n",
       "      <td>...</td>\n",
       "      <td>2.667433</td>\n",
       "      <td>2.058466</td>\n",
       "      <td>1.848006</td>\n",
       "      <td>3.135061e+05</td>\n",
       "      <td>5.504776e+05</td>\n",
       "      <td>3.325392</td>\n",
       "      <td>0.262556</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>857.316650</td>\n",
       "      <td>144.522919</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>48419.500000</td>\n",
       "      <td>2.665590</td>\n",
       "      <td>1.721625</td>\n",
       "      <td>1.490499</td>\n",
       "      <td>212.262501</td>\n",
       "      <td>106.300827</td>\n",
       "      <td>...</td>\n",
       "      <td>4.504607</td>\n",
       "      <td>2.411578</td>\n",
       "      <td>2.078014</td>\n",
       "      <td>8.499194e+05</td>\n",
       "      <td>1.027154e+06</td>\n",
       "      <td>3.068435</td>\n",
       "      <td>0.186906</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>13.066667</td>\n",
       "      <td>851.250000</td>\n",
       "      <td>315.575684</td>\n",
       "      <td>280.450012</td>\n",
       "      <td>64837.890625</td>\n",
       "      <td>-0.624075</td>\n",
       "      <td>0.691747</td>\n",
       "      <td>0.789895</td>\n",
       "      <td>247.808332</td>\n",
       "      <td>297.199982</td>\n",
       "      <td>...</td>\n",
       "      <td>3.436387</td>\n",
       "      <td>1.933112</td>\n",
       "      <td>1.188187</td>\n",
       "      <td>3.639221e+06</td>\n",
       "      <td>2.119670e+06</td>\n",
       "      <td>4.132731</td>\n",
       "      <td>0.347506</td>\n",
       "      <td>16</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>4.466667</td>\n",
       "      <td>635.766663</td>\n",
       "      <td>253.211121</td>\n",
       "      <td>237.600006</td>\n",
       "      <td>35579.738281</td>\n",
       "      <td>-0.868062</td>\n",
       "      <td>0.345004</td>\n",
       "      <td>0.729251</td>\n",
       "      <td>300.741673</td>\n",
       "      <td>241.473343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983052</td>\n",
       "      <td>1.418376</td>\n",
       "      <td>1.329144</td>\n",
       "      <td>4.870405e+06</td>\n",
       "      <td>2.246511e+06</td>\n",
       "      <td>3.808833</td>\n",
       "      <td>0.224110</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>1.366667</td>\n",
       "      <td>465.066681</td>\n",
       "      <td>187.743759</td>\n",
       "      <td>215.050003</td>\n",
       "      <td>24700.861328</td>\n",
       "      <td>-1.422475</td>\n",
       "      <td>0.099830</td>\n",
       "      <td>0.819500</td>\n",
       "      <td>295.824997</td>\n",
       "      <td>180.345016</td>\n",
       "      <td>...</td>\n",
       "      <td>3.644140</td>\n",
       "      <td>2.224552</td>\n",
       "      <td>1.707360</td>\n",
       "      <td>1.365883e+06</td>\n",
       "      <td>1.374905e+06</td>\n",
       "      <td>3.576127</td>\n",
       "      <td>0.334359</td>\n",
       "      <td>18</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>1052.849976</td>\n",
       "      <td>282.377777</td>\n",
       "      <td>243.300003</td>\n",
       "      <td>72021.414062</td>\n",
       "      <td>0.955541</td>\n",
       "      <td>1.148813</td>\n",
       "      <td>0.930376</td>\n",
       "      <td>343.291672</td>\n",
       "      <td>250.560837</td>\n",
       "      <td>...</td>\n",
       "      <td>4.556210</td>\n",
       "      <td>2.346643</td>\n",
       "      <td>1.488078</td>\n",
       "      <td>3.786963e+06</td>\n",
       "      <td>3.001285e+06</td>\n",
       "      <td>3.887931</td>\n",
       "      <td>0.446845</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>6.983333</td>\n",
       "      <td>694.066650</td>\n",
       "      <td>253.472229</td>\n",
       "      <td>233.041672</td>\n",
       "      <td>33022.226562</td>\n",
       "      <td>-0.275636</td>\n",
       "      <td>0.551870</td>\n",
       "      <td>0.701829</td>\n",
       "      <td>248.379173</td>\n",
       "      <td>241.362503</td>\n",
       "      <td>...</td>\n",
       "      <td>4.607341</td>\n",
       "      <td>2.379424</td>\n",
       "      <td>1.414736</td>\n",
       "      <td>2.214143e+06</td>\n",
       "      <td>2.229956e+06</td>\n",
       "      <td>3.992080</td>\n",
       "      <td>0.484468</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      minimum_time  maximum_time   mean_time  median_time  variance_time  \\\n",
       "0         0.966667    395.649994  131.482635   105.699997   16655.847656   \n",
       "1         0.916667    569.866638  172.020142    84.541672   33375.023438   \n",
       "2         3.500000    505.100006  150.905563    80.291664   27618.832031   \n",
       "3         3.950000    362.500000  121.906250    98.341667   12383.744141   \n",
       "4         0.000000    857.316650  144.522919     0.133333   48419.500000   \n",
       "...            ...           ...         ...          ...            ...   \n",
       "1058     13.066667    851.250000  315.575684   280.450012   64837.890625   \n",
       "1059      4.466667    635.766663  253.211121   237.600006   35579.738281   \n",
       "1060      1.366667    465.066681  187.743759   215.050003   24700.861328   \n",
       "1061      5.100000   1052.849976  282.377777   243.300003   72021.414062   \n",
       "1062      6.983333    694.066650  253.472229   233.041672   33022.226562   \n",
       "\n",
       "      kurtosis_time  skewness_time  coeff_of_var_time    iqr_time  \\\n",
       "0         -0.920655       0.638463           0.960889  212.062506   \n",
       "1         -0.561575       0.833602           1.039656  304.258337   \n",
       "2         -0.605859       0.969403           1.078092  218.149999   \n",
       "3         -0.782771       0.595389           0.893631  188.479172   \n",
       "4          2.665590       1.721625           1.490499  212.262501   \n",
       "...             ...            ...                ...         ...   \n",
       "1058      -0.624075       0.691747           0.789895  247.808332   \n",
       "1059      -0.868062       0.345004           0.729251  300.741673   \n",
       "1060      -1.422475       0.099830           0.819500  295.824997   \n",
       "1061       0.955541       1.148813           0.930376  343.291672   \n",
       "1062      -0.275636       0.551870           0.701829  248.379173   \n",
       "\n",
       "      trimmed_mean_time  ...  kurtosis_freq  skewness_freq  coeff_of_var_freq  \\\n",
       "0            120.149170  ...       4.867227       2.483317           2.018346   \n",
       "1            150.076660  ...       4.082882       2.325901           1.870382   \n",
       "2            132.926666  ...       4.611042       2.451845           2.050603   \n",
       "3            111.311668  ...       2.667433       2.058466           1.848006   \n",
       "4            106.300827  ...       4.504607       2.411578           2.078014   \n",
       "...                 ...  ...            ...            ...                ...   \n",
       "1058         297.199982  ...       3.436387       1.933112           1.188187   \n",
       "1059         241.473343  ...       0.983052       1.418376           1.329144   \n",
       "1060         180.345016  ...       3.644140       2.224552           1.707360   \n",
       "1061         250.560837  ...       4.556210       2.346643           1.488078   \n",
       "1062         241.362503  ...       4.607341       2.379424           1.414736   \n",
       "\n",
       "          iqr_freq  trimmed_mean_freq  entropy_freq  spectral_flatness  day  \\\n",
       "0     2.211316e+05       5.500495e+05      3.240957           0.281053    1   \n",
       "1     1.386454e+06       1.227904e+06      3.344774           0.230570    2   \n",
       "2     5.640596e+05       6.595294e+05      3.154835           0.232096    3   \n",
       "3     3.135061e+05       5.504776e+05      3.325392           0.262556    4   \n",
       "4     8.499194e+05       1.027154e+06      3.068435           0.186906    5   \n",
       "...            ...                ...           ...                ...  ...   \n",
       "1058  3.639221e+06       2.119670e+06      4.132731           0.347506   16   \n",
       "1059  4.870405e+06       2.246511e+06      3.808833           0.224110   17   \n",
       "1060  1.365883e+06       1.374905e+06      3.576127           0.334359   18   \n",
       "1061  3.786963e+06       3.001285e+06      3.887931           0.446845   19   \n",
       "1062  2.214143e+06       2.229956e+06      3.992080           0.484468   20   \n",
       "\n",
       "      patient_id  class  \n",
       "0              1      1  \n",
       "1              1      1  \n",
       "2              1      1  \n",
       "3              1      1  \n",
       "4              1      1  \n",
       "...          ...    ...  \n",
       "1058          55      1  \n",
       "1059          55      1  \n",
       "1060          55      1  \n",
       "1061          55      1  \n",
       "1062          55      1  \n",
       "\n",
       "[1063 rows x 27 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"full_24h\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459fdc5",
   "metadata": {},
   "source": [
    "## Depresjon classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec87dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:51:03.416400Z",
     "start_time": "2024-11-28T11:51:03.398735Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = DEPRESJON_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3de23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:51:12.400546Z",
     "start_time": "2024-11-28T11:51:12.371802Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    filename = f\"{dataset}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    datasets[part] = pd.read_csv(filepath, header=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = os.path.join(\".\", MAIN_RESULTS_DIR, \"depresjon\")\n",
    "predictions_directory = os.path.join('.', MAIN_RESULTS_DIR, DAY_WINDOWS_DIR, \"depresjon\", \"predictions\")\n",
    "os.makedirs(results_directory, exist_ok=True)\n",
    "os.makedirs(predictions_directory, exist_ok=True)\n",
    "predictions = pd.DataFrame(columns=['fold', 'classifier', 'predicted_class', 'actual_class', 'patient_id'])\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    X = datasets[part]\n",
    "    y = datasets[part]['class']\n",
    "    info = X.iloc[:, -3:]\n",
    "    group_kfold = GroupKFold(n_splits=3)\n",
    "    fold_num = 0\n",
    "    for train_idx, test_idx in group_kfold.split(X, y, groups=X['patient_id']):\n",
    "        fold_num += 1 \n",
    "        X = X.iloc[:, :-3]\n",
    "        print(\"fold: \", fold_num)\n",
    "        print(len(train_idx))\n",
    "        print(len(test_idx))\n",
    "        \n",
    "        # np.random.shuffle(train_idx)\n",
    "        # np.random.shuffle(test_idx)\n",
    "\n",
    "        print(test_idx)\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.005)\n",
    "        X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "        test_scores = []\n",
    "        for clf_type in [\"LR\", \"SVM\", \"RF\"]: \n",
    "            print(f\"    {clf_type}\")\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            print(y_pred)\n",
    "            metrics = calculate_metrics(clf, X_test, y_test)\n",
    "            print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "\n",
    "            # Save individual fold metrics\n",
    "            pd.DataFrame.from_records(test_scores).to_csv(\n",
    "                os.path.join(results_directory, f\"test_scores_{part}_fold_{clf_type}\"),\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            for idx, pred in enumerate(y_pred):\n",
    "                y_test_val = y_test[test_idx[idx]]\n",
    "\n",
    "                new_row = {\n",
    "                    'fold': fold_num,\n",
    "                    'classifier': clf_type,\n",
    "                    'predicted_class': pred, \n",
    "                    'actual_class': y_test_val, \n",
    "                    'patient_id': info.loc[test_idx[idx], 'patient_id'] \n",
    "                }\n",
    "\n",
    "                predictions = pd.concat([predictions, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        # Compute and save final scores for the fold\n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        df = pd.DataFrame([(key,) + values for key, values in final_scores.items()],\n",
    "                          columns=['Index', 'Mean', 'Stddev']).set_index('Index')\n",
    "        df.to_csv(\n",
    "            os.path.join(results_directory, f\"final_scores_{part}_fold\"),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"      {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    predictions.to_csv(\n",
    "    os.path.join(predictions_directory, f\"predictions_{part}.csv\"),\n",
    "    index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7ba5c",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    predictions = pd.read_csv(os.path.join(predictions_directory, f\"predictions_{part}.csv\"))\n",
    "    print(predictions)\n",
    "\n",
    "    grouped = predictions.groupby(['patient_id', 'classifier'])\n",
    "\n",
    "    most_common_class = (\n",
    "        grouped['predicted_class']\n",
    "        .apply(lambda x: x.mode()[0]) \n",
    "        .reset_index(name='final_predicted_class')\n",
    "    )\n",
    "\n",
    "    final_results = pd.merge(\n",
    "        most_common_class,\n",
    "        predictions[['patient_id', 'actual_class']].drop_duplicates(),\n",
    "        on='patient_id'\n",
    "    )\n",
    "\n",
    "    print(final_results)\n",
    "\n",
    "    final_results.to_csv(\n",
    "        os.path.join(predictions_directory, f\"final_predictions_{part}.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    voting_metrics = (\n",
    "    final_results.groupby('classifier')\n",
    "    .apply(lambda group: pd.Series(\n",
    "        calculate_metrics_from_df(group['actual_class'], group['final_predicted_class'])\n",
    "    ))\n",
    "    .reset_index()\n",
    "    )\n",
    "\n",
    "    print(voting_metrics)\n",
    "    \n",
    "    voting_metrics.to_csv(\n",
    "    os.path.join(predictions_directory, f\"voting_scores_{part}.csv\"),\n",
    "    index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24832b",
   "metadata": {},
   "source": [
    "## Psykose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data\", \"psykose\"))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0537c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    condition_df = condition_parts_dfs[part]\n",
    "    control_df = control_parts_dfs[part]\n",
    "    max_patient = condition_df['patient_id'].max()\n",
    "    control_df['patient_id'] += max_patient # changing numeration of patients\n",
    "    entire_df = pd.concat([condition_df, control_df], ignore_index=True)\n",
    "    datasets[part] = entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cf2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part, df in datasets.items():\n",
    "    filename = f\"{PSYKOSE_PREFIX}_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab059b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones(len(condition)), np.zeros(len(control))))\n",
    "y = pd.Series(y, dtype=int)\n",
    "\n",
    "filepath = os.path.join(PROCESSED_DATA_DIR, f\"psykose_y.csv\")\n",
    "y.to_csv(filepath, header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275cd9ef",
   "metadata": {},
   "source": [
    "## Psykose classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PSYKOSE_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cac92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    filename = f\"{dataset}_window_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    datasets[part] = pd.read_csv(filepath, header=0).dropna()\n",
    "\n",
    "#y = datasets['day']['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0994375",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = os.path.join(\".\", MAIN_RESULTS_DIR, \"psykose\")\n",
    "predictions_directory = os.path.join('.', MAIN_RESULTS_DIR, DAY_WINDOWS_DIR, \"hyperactiv\", \"predictions\")\n",
    "os.makedirs(results_directory, exist_ok=True)\n",
    "os.makedirs(predictions_directory, exist_ok=True)\n",
    "predictions = pd.DataFrame(columns=['fold', 'classifier', 'predicted_class', 'actual_class', 'patient_id'])\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    X = datasets[part]\n",
    "    y = datasets[part]['class']\n",
    "    info = X.iloc[:, -3:]\n",
    "    group_kfold = GroupKFold(n_splits=3)\n",
    "    fold_num = 0\n",
    "    for train_idx, test_idx in group_kfold.split(X, y, groups=X['patient_id']):\n",
    "        fold_num += 1 \n",
    "        X = X.iloc[:, :-3]\n",
    "        print(\"fold: \", fold_num)\n",
    "        print(len(train_idx))\n",
    "        print(len(test_idx))\n",
    "        \n",
    "        np.random.shuffle(train_idx)\n",
    "        np.random.shuffle(test_idx)\n",
    "\n",
    "        print(test_idx)\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.005)\n",
    "        X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "        test_scores = []\n",
    "        for clf_type in [\"LR\", \"SVM\", \"RF\"]: \n",
    "            print(f\"    {clf_type}\")\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            print(y_pred)\n",
    "            metrics = calculate_metrics(clf, X_test, y_test)\n",
    "            print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "\n",
    "            # Save individual fold metrics\n",
    "            pd.DataFrame.from_records(test_scores).to_csv(\n",
    "                os.path.join(results_directory, f\"test_scores_{part}_fold_{clf_type}\"),\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            for idx, pred in enumerate(y_pred):\n",
    "                y_test_val = y_test[test_idx[idx]]\n",
    "\n",
    "                new_row = {\n",
    "                    'fold': fold_num,\n",
    "                    'classifier': clf_type,\n",
    "                    'predicted_class': pred, \n",
    "                    'actual_class': y_test_val, \n",
    "                    'patient_id': info.loc[test_idx[idx], 'patient_id'] \n",
    "                }\n",
    "\n",
    "                predictions = pd.concat([predictions, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        # Compute and save final scores for the fold\n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        df = pd.DataFrame([(key,) + values for key, values in final_scores.items()],\n",
    "                          columns=['Index', 'Mean', 'Stddev']).set_index('Index')\n",
    "        df.to_csv(\n",
    "            os.path.join(results_directory, f\"final_scores_{part}_fold\"),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"      {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    predictions.to_csv(\n",
    "    os.path.join(predictions_directory, f\"predictions_{part}.csv\"),\n",
    "    index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ab9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    predictions = pd.read_csv(os.path.join(predictions_directory, f\"predictions_{part}.csv\"))\n",
    "    print(predictions)\n",
    "\n",
    "    grouped = predictions.groupby(['patient_id', 'classifier'])\n",
    "\n",
    "    most_common_class = (\n",
    "        grouped['predicted_class']\n",
    "        .apply(lambda x: x.mode()[0]) \n",
    "        .reset_index(name='final_predicted_class')\n",
    "    )\n",
    "\n",
    "    final_results = pd.merge(\n",
    "        most_common_class,\n",
    "        predictions[['patient_id', 'actual_class']].drop_duplicates(),\n",
    "        on='patient_id'\n",
    "    )\n",
    "\n",
    "    print(final_results)\n",
    "\n",
    "    final_results.to_csv(\n",
    "        os.path.join(predictions_directory, f\"final_predictions_{part}.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    voting_metrics = (\n",
    "    final_results.groupby('classifier')\n",
    "    .apply(lambda group: pd.Series(\n",
    "        calculate_metrics_from_df(group['actual_class'], group['final_predicted_class'])\n",
    "    ))\n",
    "    .reset_index()\n",
    "    )\n",
    "\n",
    "    print(voting_metrics)\n",
    "    \n",
    "    voting_metrics.to_csv(\n",
    "    os.path.join(predictions_directory, f\"voting_scores_{part}.csv\"),\n",
    "    index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40054ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-disorder-ts-ZKmnNWL8-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
